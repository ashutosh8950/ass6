# DeepFake Image Detection with CNNs, Transformers & Ensemble Approaches

This repository contains the LaTeX source and supporting materials for a research project focused on detecting DeepFake facial images using a combination of pre-trained Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). The work evaluates model efficiency and explores ensemble strategies in low-data environments.

---

## ğŸ“– Project Summary

With the rise of AI-generated content, DeepFakes have become a major challenge in verifying digital authenticity. This project aims to classify face images as real or fake using a small subset of the FaceForensics++ dataset. It compares different deep learning models and examines how combining models can improve reliability.

---

## ğŸ” Models Evaluated

- **VGG16** â€“ Classic CNN model for baseline
- **ViT** â€“ Vision Transformer architecture
- **GenConViT** â€“ CNN + Transformer hybrid
- **DeepFake-Adapter** â€“ Fine-tuned detector for DeepFake tasks

---

## âš™ï¸ Experimental Setup

- **Dataset**: 200 images (100 real, 100 fake) from FaceForensics++
- **Image Dimensions**: 128x128 pixels
- **Preprocessing Steps**:
  - Image normalization
  - Light augmentation techniques
- **Training Configuration**:
  - Loss Function: Binary Cross-Entropy
  - Optimizer: Adam
  - Early stopping applied for efficient training
- **Metrics Used**:
  - Accuracy
  - Precision
  - Recall
  - F1 Score
- **Ensemble Method**:
  - Soft voting to combine predictions from different models

---

## ğŸ“ˆ Key Outcomes

- **Top Accuracy**: 70% with VGG16
- **ViT** struggled due to the dataset size
- **Ensemble Models** showed slight gains in prediction consistency

---

## ğŸ“‚ Folder Layout

â”œâ”€â”€ images/ # Visuals and diagrams
â”‚ â”œâ”€â”€ vgg16_architecture.png
â”‚ â”œâ”€â”€ vit_architecture.png
â”‚ â”œâ”€â”€ genconvit_architecture.png
â”‚ â”œâ”€â”€ deepfake_adapter_architecture.png
â”‚ â”œâ”€â”€ sample_faces.png
â”‚ â”œâ”€â”€ confusion_cnn.png
â”‚ â”œâ”€â”€ confusion_vit.png
â”‚ â”œâ”€â”€ accuracy_bar.png
â”‚ â””â”€â”€ metric_comparison.png
â”‚
â”œâ”€â”€ DeepFake_Detection.tex # Main LaTeX document
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ references.bib # Citation file (if separated)

---

## ğŸ“¦ Requirements

To compile the LaTeX file, ensure your setup includes these packages:

- `graphicx`
- `amsmath`
- `cite`
- `caption`
- `multirow`
- `booktabs`
- `hyperref`
- `placeins` (recommended)

You can use a full LaTeX distribution like **TeX Live** or **MiKTeX**, or compile online using **Overleaf**.

---

## ğŸ“š Citation Sources

This work references the following:

- FaceForensics++ Dataset
- Research papers on VGGNet and Vision Transformers
- Hugging Face Transformers Library
- Scikit-learn for metrics and evaluation

Refer to the `.bib` file or LaTeX source for complete citation details.

---

## ğŸ‘¨â€ğŸ’» Contributor

**Ashutosh Gupta**  
Roll Number: 102203230
ğŸ“§ Email: guptaashutosh8950@gmail.com  
ğŸ« Thapar Institute of Engineering and Technology

---

## ğŸš§ Scope for Enhancement

- Add support for audio-visual multimodal detection
- Test hybrid models on larger and more diverse datasets
- Use explainability tools like Grad-CAM to visualize model focus areas

---

## ğŸ“œ License

This project is intended for academic and research usage. You are free to use or modify the materials with appropriate attribution to the original authors.
